{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape (1118, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of a kind Money maker  Try it for free Fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>link to my webcam you wanted Wanna see sexuall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re  How to manage multiple Internet connection...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SPAM]  Give her   hour rodeoEnhance your desi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Price on the netf f m   suddenlysusan Sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  labels\n",
       "0  One of a kind Money maker  Try it for free Fro...       0\n",
       "1  link to my webcam you wanted Wanna see sexuall...       0\n",
       "2  Re  How to manage multiple Internet connection...       1\n",
       "3  [SPAM]  Give her   hour rodeoEnhance your desi...       0\n",
       "4  Best Price on the netf f m   suddenlysusan Sto...       0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read dataset\n",
    "data=pd.read_csv('data.csv',sep=',', header=None)\n",
    "data.columns=['message', 'labels']\n",
    "print(f'dataset shape {data.shape}')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of spam class (380, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of a kind Money maker  Try it for free Fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>link to my webcam you wanted Wanna see sexuall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SPAM]  Give her   hour rodeoEnhance your desi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Price on the netf f m   suddenlysusan Sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Enter now  hibody      off            having N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message  labels\n",
       "0   One of a kind Money maker  Try it for free Fro...       0\n",
       "1   link to my webcam you wanted Wanna see sexuall...       0\n",
       "3   [SPAM]  Give her   hour rodeoEnhance your desi...       0\n",
       "4   Best Price on the netf f m   suddenlysusan Sto...       0\n",
       "11  Enter now  hibody      off            having N...       0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spam samples\n",
    "print(f'shape of spam class {data[data.labels==0].shape}')\n",
    "data[data.labels==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of ham class (738, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re  How to manage multiple Internet connection...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linux ie mailing list memberships reminderThis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Re  Apple Sauced   againAt      AM       on   ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Re  results for giant mass check  phew I never...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Re  RPM s  post   postun etcHave you tried reb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  labels\n",
       "2  Re  How to manage multiple Internet connection...       1\n",
       "5  linux ie mailing list memberships reminderThis...       1\n",
       "6  Re  Apple Sauced   againAt      AM       on   ...       1\n",
       "7  Re  results for giant mass check  phew I never...       1\n",
       "8  Re  RPM s  post   postun etcHave you tried reb...       1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ham samples\n",
    "print(f'shape of ham class {data[data.labels==1].shape}')\n",
    "data[data.labels==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data,n_test=0.2):\n",
    "    \"\"\"\n",
    "    Split dataset into train and test with class balance.\n",
    "    Arguments:\n",
    "    data -- dataset (format pd.DataFrame, column 'message' contains documents, column 'labels' - labels of documents)\n",
    "    n_test -- split parametr, percentage of test dataset\n",
    "    Returns:\n",
    "    train -- train dataset\n",
    "    test -- dataset\n",
    "    \"\"\"\n",
    "    len_test=int(data.shape[0]*0.2)\n",
    "    part=int(len_test/2)\n",
    "    n_1=data[data.labels==1].shape[0]\n",
    "    test_data_1=data[data.labels==1][:part]\n",
    "    train_data_1=data[data.labels==1][part:]\n",
    "    n_0=data[data.labels==0].shape[0]\n",
    "    test_data_0=data[data.labels==0][:part]\n",
    "    train_data_0=data[data.labels==0][part:]\n",
    "    test=pd.concat((test_data_1,test_data_0))\n",
    "    train=pd.concat((train_data_1,train_data_0))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (896, 2), test_shape (222, 2)\n"
     ]
    }
   ],
   "source": [
    "#split data into train and test\n",
    "train_data, test_data=split_dataset(data,n_test=0.2)\n",
    "print(f'train shape {train_data.shape}, test_shape {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(s):\n",
    "    \"\"\"\n",
    "    Method splits string into words with re pattern [A-Z,a-z]{3,}\n",
    "    Argument:\n",
    "    s -- string\n",
    "    Return:\n",
    "    words -- list of words\n",
    "    \"\"\"\n",
    "    s=s.lower()\n",
    "    pattern=r'[A-Z,a-z]{3,}'\n",
    "    words=re.findall(pattern,s)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realization of NB model\n",
    "def NB_fit(docs,labels):\n",
    "    \"\"\"\n",
    "    Naive Bayes fit method.\n",
    "    Arguments:\n",
    "    docs -- collection of documents\n",
    "    labels -- labels of documents\n",
    "    Returns:\n",
    "    [p_cl_0, p_cl_1] -- prior probability of classes\n",
    "    [N_0, N_1] -- shape of classes\n",
    "    V -- len of vocabulary(unic words from all classes)\n",
    "    [freq_0, freq_1] -- word frequencies in each classes\n",
    "    \"\"\" \n",
    "    all_words=[]\n",
    "    all_words_0=[]\n",
    "    all_words_1=[]\n",
    "    docs=np.array(docs)\n",
    "    labels=np.array(labels)\n",
    "    \n",
    "    for i in range (docs.shape[0]):\n",
    "        all_words+=split_string(docs[i].lower())\n",
    "        if labels[i]==0:\n",
    "            all_words_0+=split_string(docs[i].lower())\n",
    "        if labels[i]==1:\n",
    "            all_words_1+=split_string(docs[i].lower())      \n",
    "    print(f'The number of words = {len(all_words)}')\n",
    "    all_words_freq=Counter(all_words)\n",
    "    print(f'The number unique words = {len(all_words_freq.keys())}')\n",
    "    \n",
    "    freq_0=Counter(all_words_0)\n",
    "    freq_1=Counter(all_words_1)\n",
    "    \n",
    "    cl_0_n=Counter(labels)[0]\n",
    "    cl_1_n=Counter(labels)[1]\n",
    "    \n",
    "    p_cl_0=cl_0_n/labels.shape[0]\n",
    "    p_cl_1=cl_1_n/labels.shape[0]\n",
    "    V=len(all_words_freq.keys())\n",
    "    N_0=len(all_words_0)\n",
    "    N_1=len(all_words_1)\n",
    "    \n",
    "    print(f'prob_class=[{p_cl_0},{p_cl_1}], N_classes=[{N_0},{N_1}], Vocab={V}')\n",
    "    \n",
    "    return [p_cl_0, p_cl_1], [N_0,N_1], V, [freq_0, freq_1 ]\n",
    "    \n",
    "def NB_predict(docs,prob_classes, n_classes, V, freq, log=True, test_mode=False):\n",
    "    \"\"\"\n",
    "    Naive Bayes predict method. This method predicts classes for documents.\n",
    "    \n",
    "    Arguments:\n",
    "    docs -- collection of documents\n",
    "    prob_classes -- prior probability of classes\n",
    "    n_classes -- shape of classes\n",
    "    V -- len of vocabulary(unic words from all classes\n",
    "    freq -- word frequencies in each classes\n",
    "    log -- flag turn on using Natural logarithm for calculating conditional probability P(document|class)\n",
    "    test_mode -- flag turn on printing test information\n",
    "    \n",
    "    Return:\n",
    "    predict -- classes prediction \n",
    "    \"\"\"\n",
    "    \n",
    "    docs=np.array(docs)\n",
    "    p_cl_0=prob_classes[0]\n",
    "    p_cl_1=prob_classes[1]\n",
    "    N_0=n_classes[0]\n",
    "    N_1=n_classes[1]\n",
    "    \n",
    "    freq_0=freq[0]\n",
    "    freq_1=freq[1]\n",
    "    predict=[]\n",
    " \n",
    "    for k in range(docs.shape[0]):\n",
    "        words=split_string(docs[k].lower())\n",
    "        if log:\n",
    "            P_0=0\n",
    "            P_1=0\n",
    "        else:\n",
    "            P_0=1\n",
    "            P_1=1\n",
    "        for i in words:\n",
    "            p_wc_0=(freq_0.get(i,0) +1)/(N_0 + V)\n",
    "            p_wc_1=(freq_1.get(i,0)+1)/(N_1 +V)\n",
    "            if test_mode:\n",
    "                print(f'p_wc_0={p_wc_0}, p_wc_1={p_wc_1}')\n",
    "            if log:\n",
    "                P_0+=np.log(p_wc_0)\n",
    "                P_1+=np.log(p_wc_1)\n",
    "            else:\n",
    "                P_0*=p_wc_0\n",
    "                P_1*=p_wc_1\n",
    "                \n",
    "        if log:\n",
    "            P_0=P_0+np.log(p_cl_0)\n",
    "            P_1=P_1+np.log(p_cl_1)\n",
    "        else:\n",
    "            P_0=P_0*p_cl_0\n",
    "            P_1=P_1*p_cl_1\n",
    "        if test_mode:\n",
    "            print(f'P_0={P_0}, P_1={P_1}')\n",
    "            \n",
    "        if P_0>P_1:\n",
    "            predict.append(0)\n",
    "        else:\n",
    "            predict.append(1)\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels,predict):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of prediction\n",
    "    Arguments:\n",
    "    labels -- real labels of data\n",
    "    predict -- predict labels of data\n",
    "    Return\n",
    "    acc - acuracy\n",
    "    \"\"\"\n",
    "    labels=np.array(labels)\n",
    "    predict=np.array(predict)\n",
    "    acc=np.sum(labels==predict)/labels.shape[0]\n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words = 276021\n",
      "The number unic words = 32449\n",
      "prob_class=[0.33989266547406083,0.6601073345259392], N_classes=[107762,168259], Vocab=32449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.19499105545617"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check model and predict labels for itself\n",
    "prob_classes, n_classes, V, freq=NB_fit(data.message,data.labels)\n",
    "predictions=NB_predict(data.message,prob_classes, n_classes, V, freq,log=1)\n",
    "accuracy(data.labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words = 226343\n",
      "The number unic words = 28958\n",
      "prob_class=[0.3002232142857143,0.6997767857142857], N_classes=[80126,146217], Vocab=28958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88.28828828828829"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate prediction for test dataset\n",
    "prob_classes, n_classes, V, freq=NB_fit(train_data.message,train_data.labels)\n",
    "predictions=NB_predict(test_data.message,prob_classes, n_classes, V, freq,log=1)\n",
    "accuracy(test_data.labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it's good enough result for NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c-0 j-1\n",
    "#use NB model for predict classes for data from presentation\n",
    "train=['Chinese Beijing Chinese', 'Chinese Chinese Shanghai', 'Chinese Macao', 'Tokyo Japan Chinese']\n",
    "labels=[0,0,0,1]\n",
    "test=['Chinese Chinese Chinese Tokyo Japan',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words = 11\n",
      "The number unic words = 6\n",
      "prob_class=[0.75,0.25], N_classes=[8,3], Vocab=6\n",
      "p_wc_0=0.42857142857142855, p_wc_1=0.2222222222222222\n",
      "p_wc_0=0.42857142857142855, p_wc_1=0.2222222222222222\n",
      "p_wc_0=0.42857142857142855, p_wc_1=0.2222222222222222\n",
      "p_wc_0=0.07142857142857142, p_wc_1=0.2222222222222222\n",
      "p_wc_0=0.07142857142857142, p_wc_1=0.2222222222222222\n",
      "P_0=0.00030121377997263036, P_1=0.00013548070246744226\n",
      "predic class: [0]\n"
     ]
    }
   ],
   "source": [
    "prob_classes, n_classes, V, freq=NB_fit(train,labels)\n",
    "predictions=NB_predict(test,prob_classes, n_classes, V, freq, log=0,test_mode=True)\n",
    "print (f'predic class: {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF/IDF algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realization model NB + TF-IDF\n",
    "def NB_fit_tf(data_frame):\n",
    "    \n",
    "    \"\"\"\n",
    "    Naive Bayes + TF-IDF fit method.\n",
    "    Arguments:\n",
    "    data_frame -- dataset (format pd.DataFrame, column 'message' contains documents, column 'labels' - labels of documents)\n",
    "    Returns:\n",
    "    [p_cl_0, p_cl_1] -- prior probability of classes\n",
    "    [N_0, N_1] -- shape of classes\n",
    "    V -- len of vocabulary(unic words from all classes)\n",
    "    [freq_0, freq_1] -- word frequencies in each class\n",
    "    [idf_dic_0,idf_dic_1] -- IDF word frequencies in each class\n",
    "    \"\"\" \n",
    "    \n",
    "    data_frame['words']=data_frame.message.apply(split_string)\n",
    "    all_words=data_frame.words.sum()\n",
    "    all_words_0=data_frame[data_frame.labels==0].words.sum()\n",
    "    all_words_1=data_frame[data_frame.labels==1].words.sum()\n",
    "\n",
    "    all_words_freq=Counter(all_words)\n",
    "    freq_0=Counter(all_words_0)\n",
    "    freq_1=Counter(all_words_1)\n",
    "    \n",
    "    #TF-IDF, frequencies calculation            \n",
    "    idf_dic_0={}\n",
    "    idf_dic_1={}\n",
    "    \n",
    "    n_cl_0=data_frame[data_frame.labels==0].shape[0]\n",
    "    n_cl_1=data_frame[data_frame.labels==1].shape[0]\n",
    "    for w in freq_0.keys():\n",
    "        idf_dic_0[w]=np.sum([w in data_frame[data_frame.labels==0].words.iloc[i] for i in range(n_cl_0)])\n",
    "    for w in freq_1.keys():\n",
    "        idf_dic_1[w]=np.sum([w in data_frame[data_frame.labels==1].words.iloc[i] for i in range(n_cl_1)])\n",
    "    \n",
    "    cl_0_n=Counter(data_frame.labels)[0]\n",
    "    cl_1_n=Counter(data_frame.labels)[1]\n",
    "    \n",
    "    p_cl_0=cl_0_n/data_frame.shape[0]\n",
    "    p_cl_1=cl_1_n/data_frame.shape[0]\n",
    "    V=len(all_words_freq.keys())\n",
    "    N_0=len(all_words_0)\n",
    "    N_1=len(all_words_1)\n",
    "    \n",
    "    return [p_cl_0, p_cl_1], [N_0,N_1], V, [freq_0, freq_1 ], [idf_dic_0,idf_dic_1]\n",
    "    \n",
    "def NB_predict_tf(docs,prob_classes, n_classes, V, freq,idf_dic, log=True, test_mode=False):  \n",
    "    \"\"\"\n",
    "    Naive Bayes predict method. This method predicts classes for documents.\n",
    "    \n",
    "    Arguments:\n",
    "    docs -- collection of documents\n",
    "    prob_classes -- prior probability of classes\n",
    "    n_classes -- shape of classes\n",
    "    V -- len of vocabulary(unic words from all classes\n",
    "    freq -- word frequencies in each classes\n",
    "    idf_dic -- IDF word frequencies in each class\n",
    "    log -- flag turn on using Natural logarithm for calculating conditional probability P(document|class)\n",
    "    test_mode -- flag turn on printing test information\n",
    "    \n",
    "    Return:\n",
    "    predict -- classes prediction \n",
    "    \"\"\"\n",
    "    docs=np.array(docs)\n",
    "    p_cl_0=prob_classes[0]\n",
    "    p_cl_1=prob_classes[1]\n",
    "    N_0=n_classes[0]\n",
    "    N_1=n_classes[1]\n",
    "    \n",
    "    freq_0=freq[0]\n",
    "    freq_1=freq[1]\n",
    "    \n",
    "    idf_dic_0=idf_dic[0]\n",
    "    idf_dic_1=idf_dic[1]\n",
    "    \n",
    "    predict=[]\n",
    "    \n",
    "    for k in docs:\n",
    "        words=split_string(k)\n",
    "        words_freq=Counter(words)\n",
    "        if log:\n",
    "            P_0=0\n",
    "            P_1=0\n",
    "        else:\n",
    "            P_0=1\n",
    "            P_1=1\n",
    "        for i in words:\n",
    "            p_wc_0=(words_freq[i]/len(words))*np.log(N_0/idf_dic_0.get(i,(N_0-0.00001)))\n",
    "            p_wc_1=(words_freq[i]/len(words))*np.log(N_1/idf_dic_1.get(i,(N_1-0.00001)))\n",
    "            if log:\n",
    "                P_0+=np.log(p_wc_0)\n",
    "                P_1+=np.log(p_wc_1)\n",
    "            else:\n",
    "                P_0*=p_wc_0\n",
    "                P_1*=p_wc_1\n",
    "        if log:\n",
    "            P_0=P_0+np.log(p_cl_0)\n",
    "            P_1=P_1+np.log(p_cl_1)\n",
    "        else:\n",
    "            P_0=P_0*p_cl_0\n",
    "            P_1=P_1*p_cl_1\n",
    "        \n",
    "        if test_mode:\n",
    "            print(f'P_0={P_0}, P_1={P_1}')\n",
    "            \n",
    "        if P_0>P_1:\n",
    "            predict.append(0)\n",
    "        else:\n",
    "            predict.append(1)\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#Operation takes about 3 hours\n",
    "prob_classes, n_classes, V, freq, idf_dic=NB_fit_tf(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save IDF frequencies for each class\n",
    "with open('idf_dic.pickle', 'wb') as f:\n",
    "    pickle.dump(idf_dic,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for text classification with TF-IDF = 90.54054054054053\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes with TF-IDF algorithm\n",
    "docs_0=train_data[train_data.labels==0].shape[0]\n",
    "docs_1=train_data[train_data.labels==1].shape[0]\n",
    "\n",
    "predictions=NB_predict_tf(test_data.message,prob_classes, [docs_0,docs_1], V, freq, idf_dic, log=1)\n",
    "acc=accuracy(test_data.labels,predictions)\n",
    "print(f'Accuracy for text classification with TF-IDF = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF increase accuracy text classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
